---
title: "Function-Based Approach"
description: "A quick-start guide to using the digiqual functions."
---

DigiQual offers two ways to work: the **Functional Approach** (great for specific tasks) and the **Class-Based Approach** (recommended for full study management).

## Option 1: Functional Approach (Manual Control)

In this scenario, we generate a high-quality Latin Hypercube design. We will see that the active learning module confirms the design is sufficient and requires no further sampling.

### Generating an Experimental Design

Create a Latin Hypercube design for a simulation study involving defect size ($a$), angle ($\theta$) and roughness ($\sigma_{R}$).

```python
import pandas as pd
from digiqual.sampling import generate_lhs

# Define your variables and bounds
vars_df = pd.DataFrame(
    [
        {"Name": "Length", "Min": 0.1, "Max": 10},
        {"Name": "Angle", "Min": -90, "Max": 90},
        {"Name": "Roughness", "Min": 0, "Max": 1},
    ]
)

# Generate 1000 samples
df = generate_lhs(n=1000, seed=123, vars_df=vars_df)
print(df.head())
```

### Validating Simulation Data

Once you have your simulation results, ensure they are ready for PoD analysis.

``` python
from digiqual.diagnostics import validate_simulation
from numpy.random import default_rng

# Create a fake signal output column with some noise
rng = default_rng(123)
df['Signal'] = (df['Length'] * df['Roughness']) + rng.uniform(-1, 1, size=len(df))

df_clean, df_removed = validate_simulation(
    df=df,
    input_cols=["Length", "Angle", "Roughness"],
    outcome_col="Signal"
)

print(f"Valid rows: {len(df_clean)}")
print(f"Dropped rows: {len(df_removed)}")
```

### Checking Sample Sufficiency
We have validated data so now we want to check if we have enough samples to produce an accurate PoD Curve.

``` python
from digiqual.diagnostics import sample_sufficiency

ss = sample_sufficiency(
    df=df_clean,
    input_cols=["Length", "Angle", "Roughness"],
    outcome_col="Signal"
)
print(ss)
```

### Adaptive Refinement Check
We now run the targeted sampler. Because `generate_lhs` provides good coverage by default, we expect the adaptive module to return an empty result, confirming no more work is needed.

```python
from digiqual.adaptive import generate_targeted_samples

new_samples = generate_targeted_samples(
    df=df_clean,
    input_cols=["Length", "Angle","Roughness"],
    outcome_col="Signal",
    n_new_per_fix=5
)
```

### Running Generalised PoD Analysis
Finally, we generate the Probability of Detection curve. This pipeline automatically handles non-linear physics and heteroscedastic noise.

```python
import matplotlib.pyplot as plt
import digiqual.pod as pod
import digiqual.plotting as plot

# Prepare vectors (X = Crack Size, y = Signal)
X = df_clean['Length'].values
y = df_clean['Signal'].values
threshold = 3.0  # Detection threshold (e.g., 3.0 dB)

# A. Fit Robust Mean Model (Polynomial)
mean_model = pod.fit_robust_mean_model(X, y)

# B. Fit Variance Model (Kernel Smoothing)
residuals, bandwidth, X_eval = pod.fit_variance_model(X, y, mean_model)

# C. Infer Error Distribution (AIC Selection)
dist_name, dist_params = pod.infer_best_distribution(residuals, X, bandwidth)
print(f"Selected Distribution: {dist_name}")

# D. Compute PoD Curve & Confidence Intervals
pod_curve, mean_curve = pod.compute_pod_curve(
    X_eval, mean_model, X, residuals, bandwidth, (dist_name, dist_params), threshold
)

lower_ci, upper_ci = pod.bootstrap_pod_ci(
    X, y, X_eval, threshold, mean_model.best_degree_, bandwidth, (dist_name, dist_params)
)

# E. Plotting
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

# Plot Physics (Signal vs Size)
local_std = pod.predict_local_std(X, residuals, X_eval, bandwidth)
plot.plot_signal_model(X, y, X_eval, mean_curve, threshold, local_std=local_std, ax=ax1)

# Plot Reliability (PoD vs Size)
plot.plot_pod_curve(X_eval, pod_curve, lower_ci, upper_ci, ax=ax2)

plt.show()
```
